[package]
name = "llmur"
version = "0.0.4"
edition = "2024"
authors = ["andremachado94"]
license = "MIT"
description = "Lightweight LLM Proxy - A library for managing LLM API connections and deployments"
repository = "https://github.com/llmur/llmur"
homepage = "https://github.com/llmur/llmur"
documentation = "https://docs.rs/llmur"
keywords = ["llm", "proxy", "openai", "api", "ai"]
readme = "../README.md"

[dependencies]
axum = { workspace = true }
sqlx = { workspace = true }
serde = { workspace = true }
uuid = { workspace = true }
thiserror = { workspace = true }
redis = { workspace = true }
tracing = { workspace = true }
reqwest = { workspace = true, features = ["json"] }
serde_json = { workspace = true }
email_address = { workspace = true }
derive-getters = "0.5.0"
utoipa = { workspace = true }
rand = { workspace = true }
async-trait = { workspace = true }
paste = { workspace = true }
time = { workspace = true }
tokio = { workspace = true }
tower-http = { workspace = true }
http-body-util = { workspace = true }
lazy-regex = { workspace = true }

# Crypt
hex = { workspace = true }
aes-gcm = { workspace = true }
base64 = { workspace = true }
sha2 = { workspace = true }
hmac = { workspace = true }
chrono = "0.4.42"
log = "0.4.28"
futures = "0.3.31"
opentelemetry = { workspace = true }
