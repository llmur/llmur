use std::collections::HashMap;

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub struct ChatCompletionRequest {
	///minItems: 1
	/// A list of messages comprising the conversation so far.
	pub messages: Vec<ChatCompletionMessage>,

	/// minimum: 0
	/// maximum: 2
	/// default: 1
	/// example: 1
	/// nullable: true
	/// What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the
	/// output more random, while lower values like 0.2 will make it more focused and
	/// deterministic. We generally recommend altering this or top_p but not both.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub temperature: Option<f64>,

	/// minimum: 0
	/// maximum: 1
	/// default: 1
	/// example: 1
	/// nullable: true
	/// An alternative to sampling with temperature, called nucleus sampling, where the model
	/// considers the results of the tokens with top_p probability mass. So 0.1 means only the
	/// tokens comprising the top 10% probability mass are considered. We generally recommend
	/// altering this or temperature but not both.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub top_p: Option<f64>,

	/// nullable: true
	/// default: false
	/// If set, partial message deltas will be sent, like in ChatGPT. Tokens will be sent as
	/// data-only server-sent events as they become available, with the stream terminated by a
	/// data: [DONE] message.    #[cfg_attr(feature = "serde", serde(skip_serializing_if =
	/// "Option::is_none"))]
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub stream: Option<bool>,

	/// default: 4096
	/// The maximum number of tokens allowed for the generated answer. By default, the number of
	/// tokens the model can return will be (4096 - prompt tokens).
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub max_tokens: Option<u64>,

	/// default: 0
	/// minimum: -2
	/// maximum: 2
	/// Number between -2.0 and 2.0. Positive values penalize new tokens based on whether they
	/// appear in the text so far, increasing the model's likelihood to talk about new topics.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub presence_penalty: Option<f64>,

	/// default: 0
	/// minimum: -2
	/// maximum: 2
	/// Number between -2.0 and 2.0. Positive values penalize new tokens based on their existing
	/// frequency in the text so far, decreasing the model's likelihood to repeat the same line
	/// verbatim.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub frequency_penalty: Option<f64>,

	/// Modify the likelihood of specified tokens appearing in the completion. Accepts a json
	/// object that maps tokens (specified by their token ID in the tokenizer) to an associated
	/// bias value from -100 to 100. Mathematically, the bias is added to the logits generated by
	/// the model prior to sampling. The exact effect will vary per model, but values between -1
	/// and 1 should decrease or increase likelihood of selection; values like -100 or 100 should
	/// result in a ban or exclusive selection of the relevant token.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub logit_bias: Option<HashMap<String, i32>>,

	/// example: user-1234
	/// nullable: false
	/// A unique identifier representing your end-user, which can help Azure OpenAI to monitor and
	/// detect abuse.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub user: Option<String>,

	/// minimum: 1
	/// maximum: 128
	/// default: 1
	/// example: 1
	/// nullable: true
	/// How many chat completion choices to generate for each input message.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub n: Option<u64>,

	/// minimum: -9223372036854776000
	/// maximum: 9223372036854776000
	/// default: 0
	/// example: 1
	/// nullable: true
	/// If specified, our system will make a best effort to sample deterministically, such that
	/// repeated requests with the same seed and parameters should return the same
	/// result.Determinism is not guaranteed, and you should refer to the system_fingerprint
	/// response parameter to monitor changes in the backend.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub seed: Option<i64>,

	/// An object specifying the format that the model must output. Used to enable JSON mode.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub response_format: Option<serde_json::Value>,

	/// minItems: 1
	/// A list of tools the model may call. Currently, only functions are supported as a tool. Use
	/// this to provide a list of functions the model may generate JSON inputs for.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub tools: Option<Vec<ChatCompletionTool>>,

	/// Controls which (if any) function is called by the model. none means the model will not call
	/// a function and instead generates a message. auto means the model can pick between
	/// generating a message or calling a function. Specifying a particular function via `{"type":
	/// "function", "function": {"name": "my_function"}}` forces the model to call that function.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub tool_choice: Option<ChatCompletionToolChoice>,

	/// Up to 4 sequences where the API will stop generating further tokens.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub stop: Option<ChatCompletionStop>,

	/// A representation of configuration data for a single Azure OpenAI chat extension. This will
	/// be used by a chat completions request that should use Azure OpenAI chat extensions to
	/// augment the response behavior. The use of this configuration is compatible only with Azure
	/// OpenAI.
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub data_sources: Option<Vec<AzureChatExtensionConfiguration>>,
}
// region:    --- ChatCompletionStop
#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(untagged))]
pub enum ChatCompletionStop {
	StringStop(String),
	ArrayStop(Vec<String>),
}
// endregion: --- ChatCompletionStop

// region:    --- ChatCompletionMessage
#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(tag = "role"))]
pub enum ChatCompletionMessage {
	#[cfg_attr(feature = "serde", serde(rename = "system", alias = "system"))]
	SystemMessage { content: String },
	#[cfg_attr(feature = "serde", serde(rename = "user", alias = "user"))]
	UserMessage { content: UserMessageContent },
	#[cfg_attr(feature = "serde", serde(rename = "assistant", alias = "assistant"))]
	AssistantMessage {
		#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
		content: Option<String>,
		#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
		tool_calls: Option<Vec<AssistantToolCall>>,
		#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
		context: Option<AssistantMessageContext>,
	},
	#[cfg_attr(feature = "serde", serde(rename = "tool", alias = "tool"))]
	ToolMessage {
		// name: String,
		content: String,
		tool_call_id: String,
	},
	// TODO: Decide if should implement deprecated parameters (FunctionMessage)
}

// region:    --- Chat Completion Message Content
#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(untagged))]
pub enum UserMessageContent {
	TextContent(String),
	ArrayContentParts(Vec<UserMessageContentPart>),
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(tag = "type"))]
pub enum UserMessageContentPart {
	#[cfg_attr(feature = "serde", serde(rename = "text", alias = "text"))]
	TextContentPart { text: String },
	#[cfg_attr(feature = "serde", serde(rename = "image_url", alias = "image_url"))]
	ImageContentPart { image_url: String },
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub struct AssistantToolCall {
	pub id: String,
	#[cfg_attr(feature = "serde", serde(rename = "type"))]
	pub r#type: AssistantToolCallType,
	pub function: AssistantToolCallFunction,
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub enum AssistantToolCallType {
	#[cfg_attr(feature = "serde", serde(rename = "function", alias = "function"))]
	FunctionType,
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub struct AssistantToolCallFunction {
	pub name: String,
	pub arguments: String,
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub struct AssistantMessageContext {
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub intent: Option<String>,
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub citations: Option<Vec<AssistantContextCitation>>,
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub struct AssistantContextCitation {
	pub content: String,
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub title: Option<String>,
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub url: Option<String>,
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub filepath: Option<String>,
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub chunk_id: Option<String>,
}
// endregion  --- Chat Completion Message Content
// endregion  --- ChatCompletionMessage

// region:    --- Tools
#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(tag = "type"))]
pub enum ChatCompletionTool {
	#[cfg_attr(feature = "serde", serde(rename = "function", alias = "function"))]
	FunctionTool { function: ChatCompletionToolFunction },
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub struct ChatCompletionToolFunction {
	pub name: String,
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub description: Option<String>,
	#[cfg_attr(feature = "serde", serde(skip_serializing_if = "Option::is_none"))]
	pub parameters: Option<serde_json::Value>,
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(untagged))]
pub enum ChatCompletionToolChoice {
	StringChoice(String),
	FunctionChoice(ChatCompletionToolChoiceObject),
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(tag = "type"))]
pub enum ChatCompletionToolChoiceObject {
	#[cfg_attr(feature = "serde", serde(rename = "function", alias = "function"))]
	FunctionTool { function: ChatCompletionToolChoiceFunction },
}

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize))]
pub struct ChatCompletionToolChoiceFunction {
	pub name: String,
}

// endregion: --- Tools

// region:    --- Data Sources

#[derive(Debug, PartialEq, Clone)]
#[cfg_attr(feature = "serde", derive(serde::Serialize, serde::Deserialize), serde(tag = "type"))]
pub enum AzureChatExtensionConfiguration {
	#[cfg_attr(feature = "serde", serde(rename = "azure_cosmos_db", alias = "azure_cosmos_db"))]
	AzureCosmosDB { parameters: serde_json::Value },

	#[cfg_attr(feature = "serde", serde(rename = "azure_search", alias = "azure_search"))]
	AzureSearch { parameters: serde_json::Value },
}
// endregion: --- Data Sources

// region:    --- Tests
#[cfg(test)]
mod test {
	pub type Result<T> = core::result::Result<T, Error>;
	pub type Error = Box<dyn std::error::Error>;

	use super::*;
	use serde_json::json;

	#[test]
	fn test_azure_data_sources_01_decode_ok() -> Result<()> {
		// -- Setup & Fixtures
		let fx_request = json!({
		  "messages": [
			{
			  "role": "system",
			  "content": "You are a helpful assistant."
			},
			{
			  "role": "user",
			  "content": "Hello!"
			}
		  ],
		  "stream": true,
		  "data_sources": [{
			  "type": "azure_cosmos_db",
			  "parameters": {
				  "hello": "world"
			  }
		  }]
		})
		.to_string();

		let _data: ChatCompletionRequest = serde_json::from_str(&fx_request).unwrap();

		Ok(())
	}
}
// endregion  --- Tests
